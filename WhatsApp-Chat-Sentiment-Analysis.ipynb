{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP0PtIOE6wws34X7EQVw7l1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Important the Packages"],"metadata":{"id":"mgsIByQtlsUL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":27,"metadata":{"id":"au1CV9vwlZaM","executionInfo":{"status":"ok","timestamp":1718787524380,"user_tz":-330,"elapsed":1755,"user":{"displayName":"Riya Patel","userId":"00896112630026709782"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","from collections import Counter\n","from wordcloud import WordCloud , STOPWORDS, ImageColorGenerator"]},{"cell_type":"code","source":["#Importing Dataset\n","\n","conversation = \"1.txt\""],"metadata":{"id":"_fKgIR6Jlclg","executionInfo":{"status":"ok","timestamp":1718787525078,"user_tz":-330,"elapsed":1,"user":{"displayName":"Riya Patel","userId":"00896112630026709782"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["#Find Time And Authors\n","def date_time(s):\n","  pattern='^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+),([0-9]+)\\[?(AM|PM|am|pm)?\\]?-?' # Added a closing square bracket after (am|pm)\n","  result =re.match(pattern,s)\n","  if result:\n","    return True\n","  return False"],"metadata":{"id":"d1_gUT1am5UH","executionInfo":{"status":"ok","timestamp":1718787596752,"user_tz":-330,"elapsed":922,"user":{"displayName":"Riya Patel","userId":"00896112630026709782"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def find_author(s):\n","  s=s.split(':')\n","  if len(s)==2:\n","    return True\n","  return False"],"metadata":{"id":"LJmTmEU8nNMr","executionInfo":{"status":"ok","timestamp":1718787603839,"user_tz":-330,"elapsed":417,"user":{"displayName":"Riya Patel","userId":"00896112630026709782"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["#Find Messages\n","def message(line):\n","    split_line = line.split(' - ')\n","    datetime_str = split_line[0]\n","    date, time = datetime_str.split(', ')\n","    message = \" \".join(split_line[1:])\n","\n","    if find_author(message):\n","        split_message = message.split(': ')\n","        author = split_message[0]\n","        message = \" \".join(split_message[1:])\n","    else:\n","        author = None\n","    return date, time, author, message\n"],"metadata":{"id":"tGhuFQMMnXJh","executionInfo":{"status":"ok","timestamp":1718787607273,"user_tz":-330,"elapsed":3,"user":{"displayName":"Riya Patel","userId":"00896112630026709782"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["#Prepare The Dataset\n","data = []\n","\n","\n","with open(conversation, encoding=\"utf-8\") as fp:\n","    fp.readline()\n","    messageBuffer = []\n","    date, time, author = None, None, None\n","\n","    while True:\n","        line = fp.readline()\n","        if not line:\n","            break\n","        line = line.strip()\n","        if date_time(line):\n","            if len(messageBuffer) > 0:\n","                data.append([date, time, author, ' '.join(messageBuffer)])\n","            messageBuffer.clear()\n","            date, time, author, message = message(line)\n","            messageBuffer.append(message)\n","        else:\n","            messageBuffer.append(line)"],"metadata":{"id":"D7d7H4sgol_K","executionInfo":{"status":"ok","timestamp":1718787615071,"user_tz":-330,"elapsed":1692,"user":{"displayName":"Riya Patel","userId":"00896112630026709782"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["#Sentiment Intensity Analyzer Algorithm\n","\n","df = pd.DataFrame(data,columns=[\"Date\",\"Time\",\"Author\",\"Message\"])\n","df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n","data = df.dropna()\n","\n","import nltk\n","nltk.download('vader_lexicon')\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","sentiments = SentimentIntensityAnalyzer()\n","data[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data[\"Message\"]]\n","data[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data[\"Message\"]]\n","data[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data[\"Message\"]]\n","\n","print(data.head(10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FxKWSl1cukMZ","executionInfo":{"status":"ok","timestamp":1718789835040,"user_tz":-330,"elapsed":429,"user":{"displayName":"Riya Patel","userId":"00896112630026709782"}},"outputId":"a2ebbecb-f036-4b24-8d10-91d91b7216dc"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Empty DataFrame\n","Columns: [Date, Time, Author, Message, Positive, Negative, Neutral]\n","Index: []\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n"]}]},{"cell_type":"code","source":["#Validate the Sentiment\n","x= sum(data[\"Positive\"])\n","y= sum(data[\"Negative\"])\n","z= sum(data[\"Neutral\"])\n","\n","\n","def score(a,b,c):\n","    if a>b and a>c:\n","        print(\"Positive\")\n","    elif b>a and b>c:\n","        print(\"Negative\")\n","    else:\n","        print(\"Neutral\")\n","score(x,y,z)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5qBSIlaO1kIP","executionInfo":{"status":"ok","timestamp":1718789839807,"user_tz":-330,"elapsed":437,"user":{"displayName":"Riya Patel","userId":"00896112630026709782"}},"outputId":"65a06824-452c-4f45-cf11-ce94b3e847d6"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Neutral\n"]}]}]}